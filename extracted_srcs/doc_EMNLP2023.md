Label Words are Anchors : An Information Flow Perspective for Understanding In-Context Learning In-context learning ( ICL ) emerges as a promising capability of large language models ( LLMs ) by providing them with demonstration examples to perform diverse tasks . However , the underlying mechanism of how LLMs learn from the provided context remains under-explored . In this paper , we investigate the working mechanism of ICL through an information flow lens . Our findings reveal that label words in the demonstration examples function as anchors : In-context Learning ( ICL ) has emerged as a powerful capability alongside the development of scaledup large language models ( LLMs ) ( Brown et al . , 2020 ) . By instructing LLMs using few-shot demonstration examples , ICL enables them to perform a wide range of tasks , such as text classification ( Min et al . , 2022a ) and mathematical reasoning ( Wei et al . , 2022 ) . Despite its significance , the inner working mechanism of ICL remains an open question , garnering considerable interest from research communities ( Xie et al . , 2022 ; Dai et al . , 2022 ; Akyürek et al . , 2022 ; Li et al . , 2023b ) . In this paper , we find that the label words serve as anchors that aggregate and distribute information in ICL . We first visualize the attention interactive pattern between tokens with a GPT model ( Brown et al . , 2020 ) on sentiment analysis ( Figure 1 ) . H 2 : In deep layers , the model extracts the information from label words to form the final prediction . Two experiments are designed to validate the hypothesis using GPT2 - XL ( Radford et al . , 2019 ) and GPT-J ( Wang and Komatsuzaki , 2021 ) across several text classification benchmarks . ( 1 ) By blocking the information aggregation path to label words in certain layers , we find that such isolation in shallow layers significantly impairs model performance . This indicates that label words collect useful information during forward propagation in shallow layers . ( 2 ) We investigate the relationship between the attention distributions on the label words of the target position and the model's final prediction . In summary , these experimental findings suggest that our hypothesis holds well with large language models on real-world datasets . Drawing on insights from the information flow perspective , we explore three approaches to enhance ICL's effectiveness , efficiency , and interpretability . ( 1 ) An anchor re-weighting method is introduced , which employs a learnable vector to adjust the significance of different label words in demonstrations , leading to a 16.7% average accuracy boost compared to standard ICL baselines . ( 2 ) For quicker ICL inference , inputs are compressed into pre-calculated anchor representations since model predictions primarily rely on label word activations . Testing shows a 1.8 × speedup in inference with only a minimal performance trade-off . ( 3 ) An error analysis of ICL on GPT2 - XL demonstrates that the label confusion matrix aligns closely with the distance distribution of anchor key vectors , implying that errors might result from similar anchor representations . These promising applications further validate our hypothesis and shed light on future ICL studies for better transparency of LLMs . H 2 : In deep layers , the model makes predictions by extracting information from label words . This section aims to discover the inherent patterns in the attention interaction between tokens for a GPT model . Following common practice , we use the Taylor expansion ( Michel et al . , 2019 ) to calculate the saliency score for each element of the attention matrix : EQUATION Here , A h , l is the value of the attention matrix of the h-th attention head in the l-th layer , x is the input , and L ( x ) is the loss function of the task , e.g . , the cross-entropy objective for a classification problem . We average all attention heads to obtain the saliency matrix I l for the l-th layer . I l ( i , j ) represents the significance of the information flow from the j-th word to the i-th word for ICL . By observing I l , we can get an intuitive impression that as the layer goes deeper , demonstration label words will become more dominant for the prediction , as depicted in Figure 1 . A high S pq demonstrates a strong information extraction from label words for final decision-making . Experimental Settings We choose GPT2 - XL from the GPT series ( Radford et al . , 2019 ) as our primary model for investigation , due to its moderate model size ( of 1.5B parameters ) that is suitable for our hardware resource and its decent ICL performance ( Dai et al . , 2022 ) . For datasets , we use Stanford Sentiment Treebank Binary ( SST - 2 ) ( Socher et al . , 2013 ) for sentiment analysis , Text REtrieval Conference Question Classification ( TREC ) ( Li and Roth , 2002 ; Hovy et al . , 2001 ) for question type classification , AG's news topic classification dataset ( AGNews ) ( Zhang et al . , 2015 ) for topic classification , and EmoContext ( EmoC ) ( Chatterjee et al . , 2019 ) Results and Analysis Figure 3 reveals that : ( 1 ) in shallow layers , S pq , the significance of the information flow from label words to targeted positions , is low , while S wp , the information flow from the text part to label words is high ; ( 2 ) in deep layers , S pq , the importance of information flow from label words to the targeted position becomes the dominant one . Proposed Hypothesis Based on this , we propose the hypothesis that label words function as anchors in the ICL information flow . In shallow layers , label words gather information from demonstration examples to form semantic representations for deeper layers , while in deep layers , the model extracts the information from label words to form the final prediction . We assume that the information aggregation in ICL relies on the information flow from the text part to label tokens , which is facilitated by the transformer's attention mechanism . By manipulating the attention layer in the model to block this flow and examining the model behavior change , we validate the existence of the information aggregation process and its contribution to the final prediction . To further validate our findings on larger models , we incorporate GPT-J ( 6B ) ( Wang and Komatsuzaki , 2021 ) in experiments , which exceeds GPT2 - XL in model size and capacity . Metrics We use the following metrics to assess the impact of blocking information flow from the text part to label tokens : ( 1 ) Label Loyalty : measures the consistency of output labels with and without isolation . ( 2 ) Word Loyalty : employs the Jaccard similarity to compare the top - 5 predicted words with and without isolation , capturing more subtle model output alterations ( See Appendix C for details ) . Low loyalty indicates a profound impact of isolation on model predictions . Moreover , similar results were obtained when testing ICL with semantically unrelated labels ( refer to Appendix F .2 ) . Figures 5a and 5b delineate correlation metrics for GPT2 - XL and GPT-J , averaged across four datasets . The AUCROC l for deep layers approaches 0.8 , illustrating a strong correlation between the attention distributions on label words of the target position and the model's final prediction . Moreover , shallow layers show negligible cumulative contributions ( R l ) , with a significant increase in middle and deep layers . These results signify the crucial role of deep layers for final prediction , validating that the model extracts information from label words in deep layers to form the final prediction . In § 2.3 , we verify that the aforementioned aggregated information on label words is then extracted to form the final prediction in the deep layers . Given the considerable role these " anchors " fulfill , we find it intuitive to design ICL improvements based on them , as elaborated in § 3 . With insights from the validated hypothesis , we propose strategies to boost ICL's accuracy and inference speed . We propose an anchor re-weighting method in § 3.1 to adjust the demonstrations ' contributions and improve accuracy . In § 3.2 , we explore a context compression technique that reduces original demonstrations to anchor hidden states to speed up ICL inference . Besides , in § 3.3 , we utilize anchor distances to perform an analysis to understand the errors ICL made in real-world scenarios . These approaches corroborate our hypothesis , pointing to potential paths for future ICL enhancements . Based on our analysis in § 2 , we draw parallels between ICL and logistic regression and propose an approach to improve ICL's accuracy by reweighting label anchors . 3.1.1 Method § 2.3 illustrates a strong correlation between the model's output category and the attention distribution ( A ( q , p 1 ) , . . . , A ( q , p C ) ) on label words p 1 , . . . , p C of the target position q in deep layers . Inspired by the similarity between ICL and logistic regression , we've incorporated a learnable β i 0 into Eq . ( 7 ) , which is equivalent to adjusting the attention weights A ( q , p i ) : EQUATION Each β i 0 is a learnable parameter , set uniquely for different attention heads and layers . Owing to computational constraints , we employ GPT2 - XL for evaluation , excluding GPT-J . We compare Anchoring Re-weighting with two baselines : ( 1 ) Vanilla ICL with the same demonstration ( 1 - shot per class ) ( 2 ) Vanilla ICL , where the auxiliary training set of β is included as demonstrations ( 5 - shot per class ) for a fair comparison . As Table 1 shows , the proposed anchor reweighting significantly enhances ICL performance , particularly on the SST - 2 and EmoC datasets . Besides , adding more demonstrations for vanilla ICL may not bring a stable accuracy boost due to the potential noise introduced , as discussed in Zhao et al . ( 2021 ) . Different from vanilla ICL which utilizes the extra examples to form a demonstration , we train a re-weighting vector β to modulate label anchor contributions . The consistent improvements of our method suggest that the re-weighting mechanism could be a better alternative to utilize demonstration examples . Furthermore , it reiterates the crucial role that anchors play in ICL . We further explore a context compression technique that reduces the full demonstration to anchor hidden states for accelerating ICL inference . For AGNews , due to the length limit , we only use three demonstrations per class . Our Anchor Re-weighting method achieves the best performance overall tasks . from the demonstrations . Given the auto-regressive nature of GPT-like models , where hidden states of tokens depend solely on preceding ones , label words ' information aggregation process is independent of subsequent words . In our preliminary experiments , concatenating hidden states of label words alone was inadequate for completing the ICL task . 5 This might be due to the critical role of formatting information in helping the model to determine the output space at the target position , 6 as highlighted in Min et al . ( 2022b ) . As a solution , we amalgamate the hidden states of both the formatting and the label words , a method we've termed Hidden anchor . We compare our Hidden anchor input compression method with two equally efficient baselines . Text anchor : This method concatenates the formatting and label text with the input , as opposed to concatenating the hidden states at each layer . Hidden random : This approach concatenates the hidden states of formatting and randomly selected nonlabel words ( equal in number to Hidden anchor ) . Hidden random-top : To establish a stronger baseline , we randomly select 20 sets of non-label words in Hidden random and report the one with the highest label loyalty . The Text anchor method is included to demonstrate that the effectiveness of Hidden anchor is attributed to the aggregation of information in label words , rather than the mere text of label words . If we find that Hidden anchor surpasses Text anchor in performance , it solidifies the notion that the aggregated information within label words carries significant importance . The Hidden random method is introduced to illustrate that anchor hidden states encapsulate most of the demonstration information among all hidden states . We can see from Table 2 that the proposed compression method Hidden anchor achieves the best results among all three compression methods on all metrics and for both models . For example , with the GPT-J model , the compression method with anchor states only leads to a 1.5 accuracy drop compared to the uncompressed situation , indicating that the compression introduces negligible information loss . Further , we estimate the efficiency improvements over the original ICL . Besides , we observe that the acceleration effect is more pronounced in the GPT-J model compared to GPT2 - XL , demonstrating its great potential to apply to larger language models . Lastly , we perform an error analysis for ICL by examining the distances between the key vectors in the attention module that correspond to the label words . Furthermore , considering the distribution of query vectors q q , we employ a PCA-like method to extract the components of the key vectors along the directions with significant variations in q q , denoted as k ( see Appendix J for details ) . We anticipate that the distances between these ks can correspond to the category confusion of the model , thus revealing one possible origin of ICL errors . Here , we normalize the distances to a scale of 0 - 1 , with 0 indicating the highest degree of category confusion : EQUATION We utilize the GPT2 - XL model and TREC dataset , as the model displays varying confusion levels between categories on this dataset . We use all 500 samples of the TREC test set and use 1 demonstration per class for convenience of analysis . The heatmaps display similarity in confusing category pairs , particularly in lighter-colored blocks . This high correlation indicates that ICL makes errors in categories with similar label anchors . The existing literature on in-context learning analysis can be broadly divided into two streams , each focusing on different aspects . The first stream explores the influencing factors of ICL based on input perturbation , such as the order ( Min et al . , 2022b ) , the formatting ( Yoo et al . , 2022 ; Wei et al . , 2022 ) , and the selection of the demonstration ( Liu et al . , 2022 ) . Designing proper demonstration construc-tion strategies ( Ye et al . , 2023 ; Li et al . , 2023a ) and calibration techniques ( Zhao et al . , 2021 ; Min et al . , 2022a ) could bring clear boosts to the ICL performance . The second stream investigates the inner working mechanism of ICL through different conceptual lenses , such as making an analogy of ICL to gradient descent ( von Oswald et al . , 2022 ; Dai et al . , 2022 ) and viewing the process of ICL as a Bayesian inference ( Xie et al . , 2022 ) . In this paper , we provide a novel perspective by examining the information flow in language models to gain an understanding of ICL . Our approach offers new insights and demonstrates the potential for leveraging this understanding to improve the effectiveness , efficiency , and interpretability of ICL . In this paper , we propose a hypothesis that label words serve as anchors in in-context learning for aggregating and distributing the task-relevant information flow . Experimental results with attention manipulation and analysis of predictions correlation consolidate the hypothesis holds well in GPT2 - XL and GPT-J models . First , an anchor re-weighting method is proposed to improve ICL accuracy . Second , we explore a demonstration compression technique to accelerate ICL inference . Lastly , we showcase an analysis framework to diagnose ICL errors on a real-world dataset . These promising applications again verify the hypothesis and open up new directions for future investigations on ICL . Our study , while providing valuable insights into in-context learning ( ICL ) , has several limitations . Additionally , our hypothesis was only examined within conventional ICL paradigms , leaving other ICL paradigms such as the chain of thought prompting ( CoT ) ( Wei et al . , 2022 ) unexplored . For models , we use GPT2 - XL ( 1.5B ) ( Radford et al . , 2019 ) and GPT-J ( 6B ) ( Wang and Komatsuzaki , 2021 ) in this paper . For datasets , we use a sentiment analysis task , Stanford Sentiment Treebank Binary ( SST - 2 ) ( Socher et al . , 2013 ) , a question type classification task , Text REtrieval Conference Question Classification ( TREC ) ( Li and Roth , 2002 ; Hovy et al . , 2001 ) , a topic classification task , AG's news topic classification dataset ( AGNews ) ( Zhang et al . , 2015 ) , and an emotion classification task , Emo-Context ( EmoC ) ( Chatterjee et al . , 2019 ) .